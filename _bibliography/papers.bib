---
---

@inproceedings{
xu2021deepreduce,
title={DeepReduce: A Sparse-tensor Communication Framework for Federated Deep Learning},
author={Hang Xu and Kelly Kostopoulou and Aritra Dutta and Xin Li and Alexandros Ntoulas and Panos Kalnis},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=OAy508Q3T8},
abstract={Sparse tensors appear frequently in federated deep learning, either as a direct
artifact of the deep neural network’s gradients, or, as a result of an explicit sparsification process. Existing communication primitives are agnostic to the challenges
of deep learning; consequently, they impose unnecessary communication overhead.
This paper introduces DeepReduce, a versatile framework for the compressed
communication of sparse tensors, tailored to federated deep learning. DeepReduce
decomposes sparse tensors into two sets, values and indices, and allows both independent and combined compression of these sets. We support a variety of standard
compressors, such as Deflate for values, and Run-Length Encoding for indices.
We also propose two novel compression schemes that achieve superior results:
curve-fitting based for values, and bloom-filter based for indices. DeepReduce
is orthogonal to existing gradient sparsifiers and can be applied in conjunction
with them, transparently to the end-user, to significantly lower the communication
overhead. As a proof of concept, we implement our approach on TensorFlow
and PyTorch. Our experiments with real models demonstrate that DeepReduce
transmits 320% less data than existing sparsifiers, without affecting accuracy.},
pdf={deepreduce_a_sparse_tensor_com.pdf},
preview={conflict-sets.png},
selected={false}
}

@inproceedings{
tholoniat2022packing,
title={Packing Privacy Budget Efficiently}, 
author={Pierre Tholoniat* and Kelly Kostopoulou* and Mosharaf Chowdhury and Asaf Cidon and Roxana Geambasu and Mathias Lécuyer and Junfeng Yang},
year={2022},
url={https://arxiv.org/pdf/2212.13228.pdf},
abstract = {Machine learning (ML) models can leak information about users, and differential privacy (DP) provides a rigorous way to bound that leakage under a given budget. This DP budget can be regarded as a new type of compute resource in workloads of multiple ML models training on user data. Once it is used, the DP budget is forever consumed. Therefore, it is crucial to allocate it most efficiently to train as many models as possible. This paper presents the scheduler for privacy that optimizes for efficiency. We formulate privacy scheduling as a new type of multidimensional knapsack problem, called privacy knapsack, which maximizes DP budget efficiency. We show that privacy knapsack is NP-hard, hence practical algorithms are necessarily approximate. We develop an approximation algorithm for privacy knapsack, DPK, and evaluate it on microbenchmarks and on a new, synthetic private-ML workload we developed from the Alibaba ML cluster trace. We show that DPK: (1) often approaches the efficiency-optimal schedule, (2) consistently schedules more tasks compared to a state-of-the-art privacy scheduling algorithm that focused on fairness (1.3-1.7x in Alibaba, 1.0-2.6x in microbenchmarks), but (3) sacrifices some level of fairness for efficiency. Therefore, using DPK, DP ML operators should be able to train more models on the same amount of user data while offering the same privacy guarantee to their users.},
pdf={privacypacking.pdf},
preview={example-packing-across-blocks.png},
selected={false}
}

@inproceedings{10.1145/3600006.3613174,
author = {Kostopoulou*, Kelly and Tholoniat*, Pierre and Cidon, Asaf and Geambasu, Roxana and L\'{e}cuyer, Mathias},
title = {Turbo: Effective Caching in Differentially-Private Databases},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600006.3613174},
doi = {10.1145/3600006.3613174},
abstract = {Differentially-private (DP) databases allow for privacy-preserving analytics over sensitive datasets or data streams. In these systems, user privacy is a limited resource that must be conserved with each query. We propose Turbo, a novel, state-of-the-art caching layer for linear query workloads over DP databases. Turbo builds upon private multiplicative weights (PMW), a DP mechanism that is powerful in theory but ineffective in practice, and transforms it into a highly-effective caching mechanism, PMW-Bypass, that uses prior query results obtained through an external DP mechanism to train a PMW to answer arbitrary future linear queries accurately and "for free" from a privacy perspective. Our experiments on public Covid and CitiBike datasets show that Turbo with PMW-Bypass conserves 1.7 -- 15.9\texttimes{} more budget compared to vanilla PMW and simpler cache designs, a significant improvement. Moreover, Turbo provides support for range query workloads, such as timeseries or streams, where opportunities exist to further conserve privacy budget through DP parallel composition and warm-starting of PMW state. Our work provides a theoretical foundation and general system design for effective caching in DP databases.},
booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles},
pages = {579–594},
numpages = {16},
location = {Koblenz, Germany},
series = {SOSP '23},
pdf={turbo.pdf},
preview={tree-structured-PMW-Bypass.png},
selected={false}
}

@inproceedings{
tholoniat2024alistair,
title={Alistair: Efficient On-device Budgeting for Differentially-Private Ad-Measurement Systems}, 
author={Pierre Tholoniat* and Kelly Kostopoulou* and Peter McNeely and Prabhpreet Singh Sodhi and Anirudh Varanasi and Benjamin Case and Asaf Cidon and Roxana Geambasu and Mathias Lécuyer},
year={2024},
pdf={alistair.pdf},
preview={alistair.png},
selected={false}
}

